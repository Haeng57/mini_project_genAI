# TITLE
AI 윤리성 리스크 진단 멀티에이전트 설계 시나리오
- 본 프로젝트는 AI 서비스의 윤리적 리스크(편향성, 프라이버시 침해, 투명성 부족 등)를 진단하고, 개선 권고안을 자동으로 도출하는 멀티에이전트 시스템을 설계·구현한 실습 프로젝트입니다.

## Overview

- Objective : 특정 AI 서비스(최대 3개)에 대해 국제적 윤리 가이드라인(EU AI Act, UNESCO, OECD 등)에 기반한 윤리 리스크 진단 및 개선 권고안 자동화
- Methods : 멀티에이전트 협력 평가, 자율점검표 기반 리스크 분석, 보고서 자동 생성
- Tools : LangGraph, LangChain, Python, GPT-4o-mini(OpenAI API), FAISS, Chroma

## Features

- AI 서비스별 윤리 리스크(편향, 프라이버시, 설명가능성 등) 자동 진단
- 국제 가이드라인 기반 자율점검표 적용 및 리스크 등급화
- 개선 권고안 및 요약 보고서 자동 생성
- 진단 범위 검증 및 업데이트: 서비스 분석 이후 사전 임베딩된 데이터와 대조하여 진단 범위를 최신 정보로 갱신


## Tech Stack 

| Category   | Details                      |
|------------|------------------------------|
| Framework  | LangGraph, LangChain, Python |
| LLM        | GPT-4o-mini via OpenAI API   |
| Retrieval  | Chroma                       |


## Agents
| 에이전트명                | 주요 역할 및 설명                                                                               |
|---------------------------|-------------------------------------------------------------------------------------------------|
| 서비스 분석 에이전트       | AI 서비스 개요, 대상 기능, 주요 특징 등 정리 및 진단 범위 확정                                 |
| 범위 검증 에이전트	     | E서비스 분석 에이전트가 확정한 진단 범위를 사전 임베딩된 데이터와 대조하여 관련 정보 검증·수정 |
| 윤리 리스크 진단 에이전트  | 편향성, 개인정보, 설명가능성 등 윤리 기준별 리스크 평가                                        |
| 개선안 제안 에이전트       | 리스크 완화 및 윤리성 강화 위한 구체적 개선 방향 도출                                          |
| 리포트 작성 에이전트       | 진단 결과 및 권고사항 요약 보고서 자동 생성                                                    |


## State
- SERVICE_INFO: 진단 대상 AI 서비스 개요 및 주요 기능 정보
- SCOPE_UPDATE: 검증 에이전트가 수정·확인한 진단 범위 정보
- ETHICS_GUIDELINE: 적용할 윤리 가이드라인(예: EU AI Act, OECD 등) 및 기준 목록
- RISK_ASSESSMENT: 각 항목별 윤리 리스크 평가 결과 및 등급(편향, 프라이버시, 투명성 등)
- IMPROVEMENT_SUGGESTION: 리스크별 개선 권고안 및 구체적 실행 방안
- REPORT: 전체 진단 결과 및 요약, 권고사항을 포함한 최종 보고서

## Architecture
(그래프 이미지 예시)
```mermaid
[서비스 분석 에이전트]
        ↓
[범위 검증 에이전트]
        ↓
[윤리 리스크 진단 에이전트]
        ↓
[개선안 제안 에이전트]
        ↓
[리포트 작성 에이전트]
        ↓
[최종 보고서]         
```
- 각 에이전트는 독립적으로 작동하며, 상위 결과를 입력받아 다음 단계로 전달

## Directory Structure
```
├── data/                  # AI 서비스 관련 문서 및 가이드라인
├── agents/                # 평가 기준별 Agent 모듈 (서비스 분석, 범위 검증, 윤리 진단, 개선안, 리포트)
├── prompts/               # 프롬프트 템플릿
├── outputs/               # 평가 결과 및 보고서 저장
├── app.py                 # 실행 스크립트
└── README.md

```

## 보고서 정의(예시 프롬프트)
```
SUMMARY
- 진단 대상 서비스 및 주요 기능 요약
- 적용 윤리 가이드라인 및 평가 항목
- 핵심 리스크 진단 결과 요약(편향, 프라이버시, 투명성 등)
- 주요 개선 권고안 요약

1. 서비스 개요 및 진단 목적
2. 적용 윤리 가이드라인(출처, 주요 기준)
3. 항목별 윤리 리스크 평가 결과
   - 편향성: 진단 결과, 위험 등급, 근거
   - 프라이버시: 진단 결과, 위험 등급, 근거
   - 설명가능성: 진단 결과, 위험 등급, 근거
   - (기타 항목)
4. 리스크별 개선 권고안
5. 결론 및 향후 과제
```

## 설계 방향성 및 시나리오 요약
- 국제 기준 준수: EU AI Act, UNESCO, OECD 등 국제적 윤리 가이드라인을 진단 프레임워크에 명확히 반영
- 자율점검표 활용: 국내외 AI 윤리 자율점검표를 참고하여, 서비스 특성에 맞는 문항을 자동 선별·적용
- 진단 범위 검증·업데이트: 사전 임베딩된 데이터와 대조하여 범위 누락·변경 사항을 자동 반영
- 리스크 등급화: 위험 등급(낮음/중간/높음/심각) 및 근거를 명확히 산출, 개선 전·후 효과 추적
- 개선안 자동화: 각 리스크별로 구체적 개선 방향 및 실행 방안을 제안(예: 데이터 편향 완화, 프라이버시 강화, 설명가능성 제고 등)
- 투명성·책임성 강화: 모든 진단 과정과 결과를 투명하게 보고서에 기록, 필요시 사용자 피드백 및 외부 전문가 평가 연계
- 확장성: 최대 3개 서비스까지 동시 진단 가능, RAG 적용 문서 제한 등 현실적 개발 범위 내에서 설계

## Contributors 
- 이원행
