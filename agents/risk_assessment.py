# filepath: /Users/lwh/SKALA/mini_project_genAI/agents/risk_assessment.py
import os
import json
from typing import Dict, List, Any, Literal
from datetime import datetime
from pydantic import BaseModel, Field

from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from utils.vector_db import VectorDBManager

# ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜
class RiskAssessmentState(BaseModel):
    # ì…ë ¥ ë°ì´í„°
    ethics_guideline: Dict = Field(default_factory=dict, description="ì ìš©í•  ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸")
    service_info: Dict = Field(default_factory=dict, description="ì„œë¹„ìŠ¤ ì •ë³´")
    scope_update: Dict = Field(default_factory=dict, description="ê²€ì¦ëœ ì§„ë‹¨ ë²”ìœ„")
    
    # ì¤‘ê°„ ì²˜ë¦¬ ë°ì´í„°
    guideline_summary: str = Field(default="", description="ê°€ì´ë“œë¼ì¸ ìš”ì•½")
    risk_items: List[Dict] = Field(default_factory=list, description="ì¶”ì¶œëœ ë¦¬ìŠ¤í¬ í•­ëª© ëª©ë¡")
    current_risk_item: Dict = Field(default_factory=dict, description="í˜„ì¬ í‰ê°€ ì¤‘ì¸ ë¦¬ìŠ¤í¬ í•­ëª©")
    current_index: int = Field(default=0, description="í˜„ì¬ í‰ê°€ ì¤‘ì¸ ë¦¬ìŠ¤í¬ í•­ëª© ì¸ë±ìŠ¤")
    
    # ì ìˆ˜ ê´€ë ¨
    score_P: int = Field(default=0, description="ë°œìƒ ê°€ëŠ¥ì„± ì ìˆ˜ (1-5)")
    score_S: int = Field(default=0, description="ì‹¬ê°ë„ ì ìˆ˜ (1-5)")
    score_D: int = Field(default=0, description="íƒì§€ ìš©ì´ì„± ì ìˆ˜ (1-5)")
    score_M: int = Field(default=0, description="ì™„í™” ë‚œì´ë„ ì ìˆ˜ (1-5)")
    rationale: str = Field(default="", description="ì ìˆ˜ ì‚°ì • ê·¼ê±°")
    
    # ê³„ì‚°ëœ ë¦¬ìŠ¤í¬ ì ìˆ˜
    risk_scores: Dict = Field(default_factory=lambda: {"basic": 0, "weighted": 0}, description="ê³„ì‚°ëœ ë¦¬ìŠ¤í¬ ì ìˆ˜")
    
    # ë¦¬ìŠ¤í¬ ë“±ê¸‰
    severity_level: Dict = Field(default_factory=dict, description="ë¦¬ìŠ¤í¬ ë“±ê¸‰ ì •ë³´")
    severity_levels: List[Dict] = Field(default_factory=list, description="ëª¨ë“  í•­ëª©ì˜ ë¦¬ìŠ¤í¬ ë“±ê¸‰ ëª©ë¡")
    
    # ì»¨íŠ¸ë¡¤ ì •ë³´
    retry_count: int = Field(default=0, description="ì¬ì§„ë‹¨ ì‹œë„ íšŸìˆ˜")
    next_node: str = Field(default="", description="ë‹¤ìŒ ë…¸ë“œ")
    
    # ì¶œë ¥
    assessment_result: Dict = Field(default_factory=dict, description="ìµœì¢… ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼")
    error_message: str = Field(default="", description="ì˜¤ë¥˜ ë©”ì‹œì§€(ìˆëŠ” ê²½ìš°)")
    timestamp: str = Field(default="", description="ì‹¤í–‰ ì‹œê°„")

# ì—ì´ì „íŠ¸ ë…¸ë“œ í•¨ìˆ˜ êµ¬í˜„
def guideline_retriever(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•˜ëŠ” ë…¸ë“œ
    """
    print("ğŸ“š ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ë° ìš”ì•½ ì¤‘...")
    
    try:
        doc_id = state.ethics_guideline.get("doc_id", "")
        if not doc_id:
            # ë¬¸ì„œ IDê°€ ì—†ìœ¼ë©´ ê°€ì´ë“œë¼ì¸ ë¬¸ì„œ ê²€ìƒ‰
            db_manager = VectorDBManager()
            docs = db_manager.search(
                collection_name="ethics_guidelines",
                query="UNESCO AI Ethics Recommendations OECD AI Principles",
                k=2,
                filter={"type": "guideline"}
            )
            
            if docs:
                doc_id = docs[0].metadata.get("doc_id", "")
            else:
                raise ValueError("ê°€ì´ë“œë¼ì¸ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ê°€ì´ë“œë¼ì¸ ìš”ì•½
        llm = ChatOpenAI(model="gpt-4o-mini")
        
        # ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        db_manager = VectorDBManager()
        guideline_docs = db_manager.get_by_metadata(
            collection_name="ethics_guidelines",
            metadata_filter={"doc_id": doc_id}
        )
        
        if not guideline_docs:
            raise ValueError(f"ë¬¸ì„œ ID '{doc_id}'ì— í•´ë‹¹í•˜ëŠ” ê°€ì´ë“œë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°€ì´ë“œë¼ì¸ ë‚´ìš©
        guideline_content = "\n\n".join([doc.page_content for doc in guideline_docs[:5]])  # ì²˜ìŒ 5ê°œ ì²­í¬ë§Œ ì‚¬ìš©
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """
        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ê°€ì´ë“œë¼ì¸ ë‚´ìš©ì—ì„œ **í¸í–¥ì„±**, **í”„ë¼ì´ë²„ì‹œ**, **íˆ¬ëª…ì„±** ê´€ë ¨ ì¡°í•­ì„ 
        ìš°ì„ ìˆœìœ„(UNESCO > OECD > ê¸°íƒ€)ì— ë”°ë¼ ìš”ì•½í•´ì£¼ì„¸ìš”.
        
        ê° í•­ëª©ë³„ë¡œ ì¡°í•­ ë²ˆí˜¸ì™€ ì œëª©ì„ í¬í•¨í•˜ì—¬ í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        
        # ê°€ì´ë“œë¼ì¸ ë‚´ìš©
        {guideline_content}
        
        # ìš”ì•½ í˜•ì‹
        ## 1. í¸í–¥ì„±(Bias) ê´€ë ¨ ì¡°í•­
        | ì¶œì²˜ | ì¡°í•­ ë²ˆí˜¸ | ì œëª© | ì£¼ìš” ë‚´ìš© |
        |------|-----------|------|-----------|
        | UNESCO | ì¡°í•­ x | ì œëª© | ë‚´ìš© ìš”ì•½ |
        | OECD | ì›ì¹™ y | ì œëª© | ë‚´ìš© ìš”ì•½ |
        
        ## 2. í”„ë¼ì´ë²„ì‹œ(Privacy) ê´€ë ¨ ì¡°í•­
        (ë™ì¼í•œ í‘œ í˜•ì‹)
        
        ## 3. íˆ¬ëª…ì„±(Transparency) ê´€ë ¨ ì¡°í•­
        (ë™ì¼í•œ í‘œ í˜•ì‹)
        
        ## 4. ê¸°íƒ€ ì¤‘ìš” ìœ¤ë¦¬ ì›ì¹™
        (ë™ì¼í•œ í‘œ í˜•ì‹)
        """
        
        # LLM í˜¸ì¶œ
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | llm
        
        response = chain.invoke({"guideline_content": guideline_content})
        guideline_summary = response.content
        
        return RiskAssessmentState(
            **state.model_dump(),
            guideline_summary=guideline_summary,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        return RiskAssessmentState(
            **state.model_dump(),
            error_message=f"ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
            timestamp=datetime.now().isoformat()
        )

def risk_item_extractor(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    ì„œë¹„ìŠ¤ ì •ë³´ì™€ ê²€ì¦ëœ ë²”ìœ„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¦¬ìŠ¤í¬ í•­ëª©ì„ ì¶”ì¶œ
    """
    print("ğŸ” ë¦¬ìŠ¤í¬ í•­ëª© ì¶”ì¶œ ì¤‘...")
    
    if state.error_message:
        return state
    
    try:
        service_summary = state.service_info.get("summary", "")
        scope_update = state.scope_update
        
        if not service_summary:
            raise ValueError("ì„œë¹„ìŠ¤ ìš”ì•½ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤í¬ í•­ëª© ì¶”ì¶œ
        llm = ChatOpenAI(model="gpt-4o-mini")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """
        ë‹¹ì‹ ì€ AI ì„œë¹„ìŠ¤ ìœ¤ë¦¬ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì„œë¹„ìŠ¤ ìš”ì•½ê³¼ ê²€ì¦ëœ ë²”ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ìš” ìœ¤ë¦¬ í•­ëª©ë³„ë¡œ 
        ì ì¬ ë¦¬ìŠ¤í¬ í•­ëª©ì„ 5~7ê°œì”© ì¶”ì¶œí•˜ê³ , ê°„ë‹¨í•œ ì„¤ëª…ì„ ë§ë¶™ì—¬ ì£¼ì„¸ìš”.
        
        # ì„œë¹„ìŠ¤ ìš”ì•½
        {service_summary}
        
        # ê²€ì¦ëœ ë²”ìœ„ ì •ë³´
        {scope_update}
        
        ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¦¬ìŠ¤í¬ í•­ëª©ì„ ì‘ì„±í•˜ì„¸ìš”:
        1. í¸í–¥ì„±(Bias) ë¦¬ìŠ¤í¬
        2. í”„ë¼ì´ë²„ì‹œ(Privacy) ë¦¬ìŠ¤í¬
        3. ì„¤ëª…ê°€ëŠ¥ì„±(Explainability) ë¦¬ìŠ¤í¬
        
        ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
        ```json
        [
          {{
            "category": "í¸í–¥ì„±",
            "id": "bias_1",
            "risk_item": "ë¦¬ìŠ¤í¬ í•­ëª© ì œëª©",
            "description": "ë¦¬ìŠ¤í¬ ì„¤ëª…(1-2ë¬¸ì¥)"
          }},
          {{
            "category": "í”„ë¼ì´ë²„ì‹œ",
            "id": "privacy_1",
            "risk_item": "ë¦¬ìŠ¤í¬ í•­ëª© ì œëª©",
            "description": "ë¦¬ìŠ¤í¬ ì„¤ëª…(1-2ë¬¸ì¥)"
          }},
          ...
        ]
        ```
        """
        
        # LLM í˜¸ì¶œ
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | llm
        
        scope_update_str = json.dumps(scope_update, ensure_ascii=False)
        response = chain.invoke({
            "service_summary": service_summary,
            "scope_update": scope_update_str
        })
        
        # JSON ì‘ë‹µ íŒŒì‹±
        content = response.content
        json_start = content.find("```json") + 7 if "```json" in content else content.find("[")
        json_end = content.find("```", json_start) if "```" in content[json_start:] else len(content)
        json_str = content[json_start:json_end].strip()
        
        risk_items = json.loads(json_str)
        
        # ì²« ë²ˆì§¸ ë¦¬ìŠ¤í¬ í•­ëª©ì„ í˜„ì¬ í•­ëª©ìœ¼ë¡œ ì„¤ì •
        current_risk_item = risk_items[0] if risk_items else {}
        
        return RiskAssessmentState(
            **state.model_dump(),
            risk_items=risk_items,
            current_risk_item=current_risk_item,
            current_index=0,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        return RiskAssessmentState(
            **state.model_dump(),
            error_message=f"ë¦¬ìŠ¤í¬ í•­ëª© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}",
            timestamp=datetime.now().isoformat()
        )

def score_predictor(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    í˜„ì¬ ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•œ ì ìˆ˜ ì˜ˆì¸¡
    """
    current_index = state.current_index
    risk_items = state.risk_items
    
    # ëª¨ë“  í•­ëª©ì„ ì²˜ë¦¬í–ˆìœ¼ë©´ ì¢…ë£Œ
    if current_index >= len(risk_items):
        return state
    
    current_risk_item = risk_items[current_index]
    print(f"ğŸ§® ë¦¬ìŠ¤í¬ í•­ëª© [{current_index+1}/{len(risk_items)}] ì ìˆ˜ ì˜ˆì¸¡ ì¤‘: {current_risk_item.get('risk_item', '')}")
    
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ìŠ¤í¬ ì ìˆ˜ ì˜ˆì¸¡
        llm = ChatOpenAI(model="gpt-4o-mini")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """
        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ í•­ëª©ì˜ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ì„¸ìš”.
        
        # ë¦¬ìŠ¤í¬ í•­ëª©
        {risk_item}
        
        # ê°€ì´ë“œë¼ì¸ ìš”ì•½
        {guideline_summary}
        
        ë‹¤ìŒ 4ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ 1~5ì ì„ ë¶€ì—¬í•˜ê³ (1=ë§¤ìš° ë‚®ìŒ, 5=ë§¤ìš° ë†’ìŒ), ê° ì ìˆ˜ì— ëŒ€í•œ ê·¼ê±°ë¥¼ 2ë¬¸ì¥ ì´ë‚´ë¡œ ì„¤ëª…í•˜ì„¸ìš”:
        
        1. ë°œìƒ ê°€ëŠ¥ì„±(P): í•´ë‹¹ ë¦¬ìŠ¤í¬ê°€ ë°œìƒí•  í™•ë¥ 
        2. ì‹¬ê°ë„(S): ë°œìƒ ì‹œ ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ ì‹¬ê°ì„±
        3. íƒì§€ ìš©ì´ì„±(D): ë¦¬ìŠ¤í¬ ë°œìƒì„ ì–¼ë§ˆë‚˜ ì‰½ê²Œ íƒì§€í•  ìˆ˜ ìˆëŠ”ì§€ (1=ë§¤ìš° ì‰¬ì›€, 5=ë§¤ìš° ì–´ë ¤ì›€)
        4. ì™„í™” ë‚œì´ë„(M): ë¦¬ìŠ¤í¬ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•œ ì–´ë ¤ì›€ ì •ë„ (1=ë§¤ìš° ì‰¬ì›€, 5=ë§¤ìš° ì–´ë ¤ì›€)
        
        ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
        ```json
        {{
          "P": ì ìˆ˜(1-5),
          "S": ì ìˆ˜(1-5),
          "D": ì ìˆ˜(1-5),
          "M": ì ìˆ˜(1-5),
          "rationale": "ì ìˆ˜ ì‚°ì • ê·¼ê±° ì„¤ëª…"
        }}
        ```
        """
        
        # LLM í˜¸ì¶œ
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | llm
        
        risk_item_str = json.dumps(current_risk_item, ensure_ascii=False)
        response = chain.invoke({
            "risk_item": risk_item_str,
            "guideline_summary": state.guideline_summary
        })
        
        # JSON ì‘ë‹µ íŒŒì‹±
        content = response.content
        json_start = content.find("```json") + 7 if "```json" in content else content.find("{")
        json_end = content.find("```", json_start) if "```" in content[json_start:] else len(content)
        json_str = content[json_start:json_end].strip()
        
        scores = json.loads(json_str)
        
        return RiskAssessmentState(
            **state.model_dump(),
            current_risk_item=current_risk_item,
            score_P=scores.get("P", 0),
            score_S=scores.get("S", 0),
            score_D=scores.get("D", 0),
            score_M=scores.get("M", 0),
            rationale=scores.get("rationale", "")
        )
        
    except Exception as e:
        return RiskAssessmentState(
            **state.model_dump(),
            error_message=f"ì ìˆ˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}",
            current_risk_item=current_risk_item
        )

def score_calculator(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
    """
    P = state.score_P
    S = state.score_S
    D = state.score_D
    M = state.score_M
    
    # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°: P Ã— S
    basic_score = P * S
    
    # ê°€ì¤‘í•© ê³„ì‚°: 0.4Ã—P + 0.4Ã—S + 0.1Ã—D + 0.1Ã—M
    weighted_score = 0.4 * P + 0.4 * S + 0.1 * D + 0.1 * M
    
    print(f"ğŸ§® ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: ê¸°ë³¸={basic_score}, ê°€ì¤‘í•©={weighted_score}")
    
    return RiskAssessmentState(
        **state.model_dump(),
        risk_scores={
            "basic": basic_score,
            "weighted": weighted_score
        }
    )

def severity_classifier(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    ë¦¬ìŠ¤í¬ ë“±ê¸‰ ë¶„ë¥˜
    """
    weighted_score = state.risk_scores.get("weighted", 0)
    
    # ë“±ê¸‰ ê²°ì •
    if weighted_score <= 6:
        level = "ë‚®ìŒ"
    elif weighted_score <= 12:
        level = "ì¤‘ê°„"
    elif weighted_score <= 18:
        level = "ë†’ìŒ"
    else:
        level = "ì‹¬ê°"
    
    print(f"ğŸ” ë¦¬ìŠ¤í¬ ë“±ê¸‰ ë¶„ë¥˜: {level} (ì ìˆ˜: {weighted_score})")
    
    severity = {
        "level": level,
        "thresholds": [
            {"range": "1-6", "level": "ë‚®ìŒ"},
            {"range": "7-12", "level": "ì¤‘ê°„"},
            {"range": "13-18", "level": "ë†’ìŒ"},
            {"range": "19-25", "level": "ì‹¬ê°"}
        ]
    }
    
    # í˜„ì¬ ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•œ ê²°ê³¼ ì €ì¥
    current_item = state.current_risk_item.copy()
    current_item.update({
        "scores": {
            "P": state.score_P,
            "S": state.score_S,
            "D": state.score_D,
            "M": state.score_M
        },
        "risk_scores": state.risk_scores,
        "severity_level": level,
        "rationale": state.rationale
    })
    
    # ì²˜ë¦¬ëœ í•­ëª© ì¶”ê°€
    severity_levels = state.severity_levels.copy()
    severity_levels.append({
        "item_id": current_item.get("id", f"item_{state.current_index}"),
        "category": current_item.get("category", ""),
        "risk_item": current_item.get("risk_item", ""),
        "level": level,
        "weighted_score": weighted_score
    })
    
    # ë¦¬ìŠ¤í¬ í•­ëª© ë°°ì—´ ì—…ë°ì´íŠ¸
    updated_risk_items = state.risk_items.copy()
    updated_risk_items[state.current_index] = current_item
    
    # ë‹¤ìŒ ì¸ë±ìŠ¤ë¡œ ì´ë™
    next_index = state.current_index + 1
    next_item = {}
    if next_index < len(updated_risk_items):
        next_item = updated_risk_items[next_index]
    
    return RiskAssessmentState(
        **state.model_dump(),
        risk_items=updated_risk_items,
        severity_level=severity,
        severity_levels=severity_levels,
        current_index=next_index,
        current_risk_item=next_item
    )

def loop_controller(state: RiskAssessmentState) -> RiskAssessmentState:
    """
    ì§„ë‹¨ ë£¨í”„ ì œì–´
    """
    # ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì™„ë£Œ í™•ì¸
    if state.current_index >= len(state.risk_items):
        # ê²°ê³¼ ì €ì¥
        doc_id = f"risk_assessment_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        # ChromaDBì— ì €ì¥
        assessment_result = {
            "service_name": state.service_info.get("service_name", ""),
            "risk_items": state.risk_items,
            "severity_levels": state.severity_levels,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            db_manager = VectorDBManager()
            saved_id = db_manager.add_document(
                collection_name="risk_assessments",
                content=json.dumps(assessment_result, ensure_ascii=False),
                metadata={
                    "type": "risk_assessment",
                    "service_name": state.service_info.get("service_name", ""),
                    "timestamp": datetime.now().isoformat()
                },
                doc_id=doc_id
            )[0]
            
            # ë†’ìŒ ë˜ëŠ” ì‹¬ê° ë“±ê¸‰ í™•ì¸
            high_risks = [item for item in state.severity_levels 
                         if item.get("level") in ["ë†’ìŒ", "ì‹¬ê°"]]
            
            # ë‹¤ìŒ ë…¸ë“œ ê²°ì •
            if state.retry_count < 3 and high_risks:
                next_node = "ScorePredictor"
                retry_count = state.retry_count + 1
                print(f"âš ï¸ ë†’ì€ ë¦¬ìŠ¤í¬ í•­ëª© ë°œê²¬: ì¬ì§„ë‹¨ ì‹œë„ ({retry_count}/3)")
            else:
                next_node = "ImprovementAgent"
                retry_count = state.retry_count
                print("âœ… ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì™„ë£Œ: ê°œì„ ì•ˆ ì œì•ˆ ë‹¨ê³„ë¡œ ì´ë™")
            
            return RiskAssessmentState(
                **state.model_dump(),
                assessment_result={
                    "doc_id": saved_id,
                    "risk_items": state.risk_items,
                    "severity_levels": state.severity_levels
                },
                next_node=next_node,
                retry_count=retry_count
            )
            
        except Exception as e:
            return RiskAssessmentState(
                **state.model_dump(),
                error_message=f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                next_node="ImprovementAgent"  # ì˜¤ë¥˜ ë°œìƒí•´ë„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
            )
    else:
        # ë‹¤ìŒ í•­ëª© ì²˜ë¦¬ë¥¼ ìœ„í•´ ScorePredictorë¡œ ëŒì•„ê°
        return RiskAssessmentState(
            **state.model_dump(),
            next_node="ScorePredictor"
        )

# ì›Œí¬í”Œë¡œìš° ì œì–´ í•¨ìˆ˜
def determine_next_step(state: RiskAssessmentState) -> Literal["process_next", "finalize"]:
    """ëª¨ë“  ë¦¬ìŠ¤í¬ í•­ëª© ì²˜ë¦¬ ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
    if state.current_index < len(state.risk_items):
        return "process_next"
    return "finalize"

def determine_agent_path(state: RiskAssessmentState) -> str:
    """ë‹¤ìŒ ì—ì´ì „íŠ¸ ê²½ë¡œ ê²°ì •"""
    return state.next_node if state.next_node else "ImprovementAgent"

# ê·¸ë˜í”„ êµ¬ì„±
def create_risk_assessment_agent() -> StateGraph:
    """ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(RiskAssessmentState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("GuidelineRetriever", guideline_retriever)
    workflow.add_node("RiskItemExtractor", risk_item_extractor)
    workflow.add_node("ScorePredictor", score_predictor)
    workflow.add_node("ScoreCalculator", score_calculator)
    workflow.add_node("SeverityClassifier", severity_classifier)
    workflow.add_node("LoopController", loop_controller)
    
    # ê¸°ë³¸ í”Œë¡œìš°
    workflow.add_edge("GuidelineRetriever", "RiskItemExtractor")
    workflow.add_edge("RiskItemExtractor", "ScorePredictor")
    workflow.add_edge("ScorePredictor", "ScoreCalculator")
    workflow.add_edge("ScoreCalculator", "SeverityClassifier")
    workflow.add_edge("SeverityClassifier", "LoopController")
    
    # ì¡°ê±´ë¶€ ë¶„ê¸°
    workflow.add_conditional_edges(
        "LoopController",
        determine_next_step,
        {
            "process_next": "ScorePredictor",
            "finalize": END
        }
    )
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("GuidelineRetriever")
    
    return workflow

# ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def run_risk_assessment(service_info: Dict, scope_update: Dict, ethics_guideline: Dict = None) -> Dict:
    """ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ì‹œì‘")
    
    # ê·¸ë˜í”„ ìƒì„± ë° ì»´íŒŒì¼
    graph = create_risk_assessment_agent()
    app = graph.compile()
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    initial_state = RiskAssessmentState(
        service_info=service_info,
        scope_update=scope_update,
        ethics_guideline=ethics_guideline or {}
    )
    
    result = app.invoke(initial_state)
    
    # ê²°ê³¼ ì¶œë ¥
    if result.error_message:
        print(f"âŒ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì‹¤íŒ¨: {result.error_message}")
    else:
        print(f"âœ… ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì™„ë£Œ: {len(result.risk_items)} í•­ëª© í‰ê°€ë¨")
        
        # ë“±ê¸‰ë³„ í•­ëª© ìˆ˜ ê³„ì‚°
        severity_counts = {}
        for level in result.severity_levels:
            category = level.get("level", "ì•Œ ìˆ˜ ì—†ìŒ")
            severity_counts[category] = severity_counts.get(category, 0) + 1
        
        print("ğŸ“Š ë“±ê¸‰ë³„ í•­ëª© ìˆ˜:")
        for level, count in severity_counts.items():
            print(f"  - {level}: {count}ê°œ")
    
    # í‰ê°€ ê²°ê³¼ ë°˜í™˜
    return {
        "assessment_result": result.assessment_result,
        "next_node": result.next_node,
        "retry_count": result.retry_count
    }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
    test_service_info = {
        "service_name": "AI ì˜ìƒ ë¶„ì„ ì„œë¹„ìŠ¤",
        "company": "í…ŒìŠ¤íŠ¸íšŒì‚¬",
        "service_category": "ì˜ìƒë¶„ì„",
        "features": ["ì–¼êµ´ ì¸ì‹", "í–‰ë™ ë¶„ì„", "ê°ì • ì¸ì‹"],
        "summary": "ì´ ì„œë¹„ìŠ¤ëŠ” CCTV ì˜ìƒì—ì„œ ì–¼êµ´ì„ ì¸ì‹í•˜ê³  í–‰ë™ê³¼ ê°ì •ì„ ë¶„ì„í•˜ëŠ” AI ê¸°ë°˜ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤."
    }
    
    test_scope_update = {
        "validated_scope": {
            "included_features": ["ì–¼êµ´ ì¸ì‹", "í–‰ë™ ë¶„ì„", "ê°ì • ì¸ì‹"],
            "priority_areas": ["í”„ë¼ì´ë²„ì‹œ", "í¸í–¥ì„±"]
        }
    }
    
    run_risk_assessment(test_service_info, test_scope_update)