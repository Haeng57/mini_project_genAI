from typing import Dict, List, Any, Optional
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, END
import json
from datetime import datetime
from pydantic import BaseModel, Field
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv

load_dotenv()

# ìƒíƒœ ì •ì˜
class EthicalRiskState(BaseModel):
    # ì…ë ¥ ì •ë³´
    service_info: Dict[str, Any] = Field(default_factory=dict)
    
    # ê°€ì´ë“œë¼ì¸ ê´€ë ¨ ì •ë³´
    guideline_summary: Dict[str, List[Dict[str, str]]] = Field(default_factory=dict)
    
    # ë¦¬ìŠ¤í¬ ê´€ë ¨ ì •ë³´
    risk_items: List[Dict[str, Any]] = Field(default_factory=list)
    scores: Dict[str, Any] = Field(default_factory=dict)
    risk_scores: Dict[str, Any] = Field(default_factory=dict)
    severity_levels: List[Dict[str, str]] = Field(default_factory=list)
    rationale: Dict[str, str] = Field(default_factory=dict)
    
    # ì›Œí¬í”Œë¡œìš° ì œì–´ ì •ë³´
    assessment_status: str = "pending"
    retry_count: int = 0
    next_node: Optional[str] = None
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())
    error_message: Optional[str] = None
    
    # ChromaDB ì—°ê²° ì •ë³´
    risk_assessments: List[Dict[str, Any]] = Field(default_factory=list)
    
    def dict(self) -> Dict[str, Any]:
        """ìƒíƒœ ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "service_info": self.service_info,
            "guideline_summary": self.guideline_summary,
            "risk_items": self.risk_items,
            "scores": self.scores,
            "risk_scores": self.risk_scores,
            "severity_levels": self.severity_levels,
            "rationale": self.rationale,
            "assessment_status": self.assessment_status,
            "retry_count": self.retry_count,
            "next_node": self.next_node,
            "timestamp": self.timestamp,
            "error_message": self.error_message,
            "risk_assessments": self.risk_assessments
        }


# LLM ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4o-mini",  # READMEì— ëª…ì‹œëœ ëª¨ë¸
    temperature=0.2
)

# ChromaDB ì—°ê²° ì„¤ì •
def get_vector_store():
    """ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì—°ê²°"""
    embedding_function = HuggingFaceEmbeddings(model_name="nlpai-lab/KURE-v1")
    vector_store = Chroma(
        persist_directory="./vector_store",
        embedding_function=embedding_function,
        collection_name="ethics_guidelines"  # ì½œë ‰ì…˜ëª… ëª…ì‹œ
    )
    return vector_store


# ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ë…¸ë“œ
def guideline_retriever(state: EthicalRiskState) -> EthicalRiskState:
    """
    AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ì„ ê²€ìƒ‰í•˜ì—¬ 5ëŒ€ ìœ¤ë¦¬ ì°¨ì›ë³„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    try:
        # ë²¡í„° ìŠ¤í† ì–´ ì—°ê²°
        vector_store = get_vector_store()
        
        # 5ëŒ€ ìœ¤ë¦¬ ì°¨ì›
        ethic_dimensions = [
            "ê³µì •ì„±", "í”„ë¼ì´ë²„ì‹œ", "íˆ¬ëª…ì„±", "ì±…ì„ì„±", "ì•ˆì „ì„±"
        ]
        
        guideline_summary = {}
        
        # ê° ì°¨ì›ë³„ë¡œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
        for dimension in ethic_dimensions:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            query = f"AI {dimension} ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸"
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (ìµœëŒ€ 5ê°œ ë¬¸ì„œ) - í•„í„° ì œê±° ë˜ëŠ” ìˆ˜ì •
            results = vector_store.similarity_search(
                query=query,
                k=5
            )
            
            # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            guidelines = []
            for doc in results:
                guidelines.append({
                    "source": doc.metadata.get("file_name", "Unknown"),
                    "content": doc.page_content,
                    "page": doc.metadata.get("page_number", 0)
                })
            
            guideline_summary[dimension] = guidelines
        
        # ê°€ì´ë“œë¼ì¸ ìš”ì•½ ìƒì„±
        system_prompt = """
        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ìœ¤ë¦¬ ì°¨ì›(ê³µì •ì„±, í”„ë¼ì´ë²„ì‹œ, íˆ¬ëª…ì„±, ì±…ì„ì„±, ì•ˆì „ì„±)ì— ëŒ€í•œ
        ê°€ì´ë“œë¼ì¸ì„ ìš”ì•½í•˜ê³ , ê° ì°¨ì›ì˜ 1-5ì  ì²™ë„ í‰ê°€ ê¸°ì¤€ì„ í‘œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        human_prompt = f"""
        ë‹¤ìŒì€ 5ëŒ€ ìœ¤ë¦¬ ì°¨ì›ë³„ë¡œ ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸ ë‚´ìš©ì…ë‹ˆë‹¤:
        
        {json.dumps(guideline_summary, ensure_ascii=False, indent=2)}
        
        ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ìœ¤ë¦¬ ì°¨ì›(ê³µì •ì„±, í”„ë¼ì´ë²„ì‹œ, íˆ¬ëª…ì„±, ì±…ì„ì„±, ì•ˆì „ì„±)ì˜ ì£¼ìš” í‰ê°€ ê¸°ì¤€ì„ ìš”ì•½í•˜ê³ ,
        ê° ì°¨ì›ì˜ 1-5ì  ì²™ë„ í‰ê°€ ê¸°ì¤€ì„ í‘œë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        # LLMìœ¼ë¡œ ê°€ì´ë“œë¼ì¸ ìš”ì•½
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = llm.invoke(messages)
        
        # ìš”ì•½ ê²°ê³¼ ì €ì¥
        state.guideline_summary = guideline_summary
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ìš”ì•½ ê²°ê³¼ ì €ì¥
        vector_store.add_texts(
            texts=[response.content],
            metadatas=[{
                "type": "guideline_summary",
                "timestamp": datetime.now().isoformat(),
                "dimensions": ",".join(ethic_dimensions)
            }]
        )
        
        return state
        
    except Exception as e:
        state.error_message = f"ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ë¦¬ìŠ¤í¬ í•­ëª© ì¶”ì¶œ ë…¸ë“œ
def risk_item_extractor(state: EthicalRiskState) -> EthicalRiskState:
    """
    ì„œë¹„ìŠ¤ ì •ë³´ë¡œë¶€í„° 5ëŒ€ ìœ¤ë¦¬ ì°¨ì›ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ í•­ëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        # ì„œë¹„ìŠ¤ ì •ë³´ ì¶”ì¶œ
        service_info_text = json.dumps(state.service_info, ensure_ascii=False, indent=2)
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        system_prompt = """
        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ AI ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, 
        5ëŒ€ ìœ¤ë¦¬ ì°¨ì›(ê³µì •ì„±/í”„ë¼ì´ë²„ì‹œ/íˆ¬ëª…ì„±/ì±…ì„ì„±/ì•ˆì „ì„±) ê¸°ì¤€ìœ¼ë¡œ 
        5~7ê°œì˜ ì ì¬ì  ë¦¬ìŠ¤í¬ í•­ëª©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
        
        ì¶œë ¥ì€ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
        ```json
        [
            {
                "id": "risk_1",
                "dimension": "ê³µì •ì„±",
                "title": "ë¦¬ìŠ¤í¬ ì œëª©",
                "description": "ë¦¬ìŠ¤í¬ ì„¤ëª…"
            },
            ...
        ]
        ```
        """
        
        human_prompt = f"""
        ## AI ì„œë¹„ìŠ¤ ì •ë³´
        ```json
        {service_info_text}
        ```
        
        ìœ„ ì„œë¹„ìŠ¤ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” 5ëŒ€ ìœ¤ë¦¬ ì°¨ì›ë³„ ì ì¬ ë¦¬ìŠ¤í¬ë¥¼ 5~7ê°œ ì¶”ì¶œí•˜ê³ , 
        ê° í•­ëª©ì´ ì–´ëŠ ì°¨ì›(ê³µì •ì„±/í”„ë¼ì´ë²„ì‹œ/íˆ¬ëª…ì„±/ì±…ì„ì„±/ì•ˆì „ì„±)ì— í•´ë‹¹í•˜ëŠ”ì§€ í‘œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        # JSON íŒŒì„œ ì„¤ì •
        parser = JsonOutputParser()
        
        # ë©”ì‹œì§€ ìƒì„±
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        # LLMìœ¼ë¡œ ë¦¬ìŠ¤í¬ ì¶”ì¶œ
        response = llm.invoke(messages)
        
        # JSON ì¶”ì¶œ
        try:
            # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_content = response.content
            if "```json" in json_content:
                json_content = json_content.split("```json")[1].split("```")[0].strip()
            elif "```" in json_content:
                json_content = json_content.split("```")[1].split("```")[0].strip()
            
            risk_items = json.loads(json_content)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state.risk_items = risk_items
            
        except Exception as e:
            state.error_message = f"ë¦¬ìŠ¤í¬ í•­ëª© JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
            state.assessment_status = "failed"
        
        return state
        
    except Exception as e:
        state.error_message = f"ë¦¬ìŠ¤í¬ í•­ëª© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ì ìˆ˜ ì˜ˆì¸¡ ë…¸ë“œ
def score_predictor(state: EthicalRiskState) -> EthicalRiskState:
    """
    ê° ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•´ 1~5ì  ì²™ë„ë¡œ ì ìˆ˜ë¥¼ í‰ê°€í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """
    try:
        # ë¦¬ìŠ¤í¬ í•­ëª© ë° ê°€ì´ë“œë¼ì¸ ìš”ì•½ ì¶”ì¶œ
        risk_items = state.risk_items
        guideline_summary = state.guideline_summary
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        scores = {}
        rationale = {}
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        system_prompt = """
        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•´ í•´ë‹¹ ì°¨ì›ì˜ 1~5ì  ì²™ë„ì— ë”°ë¼ 
        ì ìˆ˜ë¥¼ í‰ê°€í•˜ê³ , 2ë¬¸ì¥ ì´ë‚´ì˜ ê°„ê²°í•œ ê·¼ê±°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ê° ìœ¤ë¦¬ ì°¨ì›ë³„ í‰ê°€ ê¸°ì¤€:
        1) ê³µì •ì„±(Fairness): ì„±ë³„Â·ì—°ë ¹Â·ì¥ì• Â·ì§€ì—­Â·ì¸ì¢…Â·ì¢…êµ ë“± ê°œì¸ íŠ¹ì„±ì— ë”°ë¥¸ í¸í–¥ê³¼ ì°¨ë³„ ìµœì†Œí™”
        - 1ì : í¸í–¥ ì—¬ë¶€ í‰ê°€ í”„ë¡œì„¸ìŠ¤ ì „í˜€ ì—†ìŒ
        - 2ì : ê¸°ë³¸ì  ì¸ì‹ ìˆìœ¼ë‚˜ ì‹¤ì§ˆì  ì¡°ì¹˜ ë¶€ì¬
        - 3ì : ì¼ë¶€ ë°ì´í„° ê²€ì¦ ìˆìœ¼ë‚˜ ì²´ê³„ì ì´ì§€ ì•ŠìŒ
        - 4ì : ì²´ê³„ì  í¸í–¥ í‰ê°€ì™€ ì¼ë¶€ ì§‘ë‹¨ ê°„ ì„±ëŠ¥ ì°¨ì´ ëª¨ë‹ˆí„°ë§
        - 5ì : ë°ì´í„°Â·ëª¨ë¸ í‰ê°€ ì‹œ ì£¼ìš” ì§‘ë‹¨ ê°„ ì„±ëŠ¥ ì°¨ì´ 2% ë¯¸ë§Œ

        2) í”„ë¼ì´ë²„ì‹œ(Privacy): ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•œ ì‚¬ì „ í”„ë¼ì´ë²„ì‹œ ì˜í–¥í‰ê°€(PIA) ë° ì•”í˜¸í™”Â·ìµëª…í™” ì¡°ì¹˜ ì ìš©
        - 1ì : PIA ë¯¸ì‹¤ì‹œ ë° ë¹„ì‹ë³„í™” ì ˆì°¨ ë¶€ì¬
        - 2ì : ê¸°ì´ˆì  ê°œì¸ì •ë³´ ì‹ë³„ ì¡°ì¹˜ë§Œ ì¡´ì¬
        - 3ì : ë¶€ë¶„ì  PIA ë° ì¼ë¶€ ì•”í˜¸í™” ì¡°ì¹˜
        - 4ì : ì²´ê³„ì  PIAì™€ ëŒ€ë¶€ë¶„ì˜ ë°ì´í„° ì•”í˜¸í™”
        - 5ì : ì „ìˆ˜ PIA ìˆ˜í–‰ ë° ì•”í˜¸í™”Â·ì ‘ê·¼ í†µì œ ì²´ê³„ ì™„ì „ êµ¬ì¶•

        3) íˆ¬ëª…ì„±(Transparency): ì˜ì‚¬ê²°ì • ê·¼ê±°ì™€ ì²˜ë¦¬ ê³¼ì •ì„ ì´í•´ê´€ê³„ìê°€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì„¤ëª… ê°€ëŠ¥ì„± ë³´ì¥
        - 1ì : ê²°ê³¼ì˜ ê·¼ê±°ë¥¼ ì „í˜€ ì œê³µí•˜ì§€ ì•ŠìŒ
        - 2ì : ìµœì†Œí•œì˜ ê²°ê³¼ ì„¤ëª…ë§Œ ì œê³µ
        - 3ì : ë¶€ë¶„ì  ì„¤ëª… ë° ì¼ë¶€ ì˜ì‚¬ê²°ì • ê³¼ì • ê³µê°œ
        - 4ì : ìƒì„¸í•œ ì„¤ëª…ê³¼ ì£¼ìš” ì˜ì‚¬ê²°ì • ê³¼ì • ê³µê°œ
        - 5ì : ëª¨ë¸ ë¡œì§Â·ë°ì´í„° ì¶œì²˜ ë¬¸ì„œí™”ë¡œ ì‚¬ìš©ì ì§ˆì˜ ì‘ë‹µ ê°€ëŠ¥

        4) ì±…ì„ì„±(Accountability): ìœ¤ë¦¬ì  ë¬¸ì œì— ëŒ€í•œ ì±…ì„ ë¶€ë‹´ ë° ë…ë¦½ ê°ì‚¬Â·ë³´ê³  ì²´ê³„ ë§ˆë ¨
        - 1ì : ì±…ì„ ì£¼ì²´ ë° ì ˆì°¨ ì „ë¬´
        - 2ì : ê¸°ë³¸ì  ë‹´ë‹¹ì ì§€ì •ë§Œ ìˆìŒ
        - 3ì : ë¶€ë¶„ì  ì±…ì„ ì²´ê³„ì™€ ê°„í—ì  ê²€í† 
        - 4ì : ëª…í™•í•œ ì±…ì„ ì²´ê³„ì™€ ì •ê¸°ì  ë‚´ë¶€ ê²€í† 
        - 5ì : ì •ê¸°ì  ìœ¤ë¦¬ì˜í–¥í‰ê°€Â·ì™¸ë¶€ ê°ì‚¬ë¥¼ í†µí•œ ê±°ë²„ë„ŒìŠ¤ ì™„ì „ ì‘ë™

        5) ì•ˆì „ì„±(Safety & Robustness): ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜Â·ê³µê²©ìœ¼ë¡œë¶€í„° ì•ˆì •ì„± ìœ ì§€ë¥¼ ìœ„í•œ ì·¨ì•½ì  ë¶„ì„ê³¼ ëŒ€ì‘ ì ˆì°¨ êµ¬ì¶•
        - 1ì : ì·¨ì•½ì  ì§„ë‹¨Â·ëª¨ë‹ˆí„°ë§ ì „ë¬´
        - 2ì : ê¸°ë³¸ì  ë³´ì•ˆ ì ê²€ë§Œ ì‹œí–‰
        - 3ì : ì£¼ê¸°ì  ì·¨ì•½ì  ë¶„ì„ ë° ê¸°ë³¸ ëŒ€ì‘ì±…
        - 4ì : í¬ê´„ì  ì·¨ì•½ì  ë¶„ì„ ë° ì²´ê³„ì  ëŒ€ì‘ ì ˆì°¨
        - 5ì : ìœ„í˜‘ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ìë™ ëŒ€ì‘ ì²´ê³„ ì™„ë¹„

        ì¶œë ¥ì€ ë‹¤ìŒ JSON í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
        ```json
        {
            "score": 3,
            "rationale": "í‰ê°€ ê·¼ê±°ë¥¼ ê°„ê²°í•˜ê²Œ ì‘ì„±"
        }
        ```
        """
        
        # ê° ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•´ ì ìˆ˜ í‰ê°€
        for risk in risk_items:
            risk_id = risk["id"]
            dimension = risk["dimension"]
            title = risk["title"]
            description = risk["description"]
            
            # í•´ë‹¹ ì°¨ì›ì˜ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ
            dimension_guidelines = guideline_summary.get(dimension, [])
            guidelines_text = "\n\n".join([
                f"ì¶œì²˜: {item['source']}\në‚´ìš©: {item['content']}" 
                for item in dimension_guidelines
            ])
            
            human_prompt = f"""
            ## ë¦¬ìŠ¤í¬ í•­ëª©
            - ID: {risk_id}
            - ì°¨ì›: {dimension}
            - ì œëª©: {title}
            - ì„¤ëª…: {description}
            
            ## ê´€ë ¨ ê°€ì´ë“œë¼ì¸
            {guidelines_text}
            
            ìœ„ ë¦¬ìŠ¤í¬ í•­ëª©ì— ëŒ€í•´ 1~5ì  ì²™ë„ë¡œ ì ìˆ˜ë¥¼ í‰ê°€í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
            """
            
            # ë©”ì‹œì§€ ìƒì„±
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=human_prompt)
            ]
            
            # LLMìœ¼ë¡œ ì ìˆ˜ ì˜ˆì¸¡
            response = llm.invoke(messages)
            
            # JSON ì¶”ì¶œ
            try:
                # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                json_content = response.content
                if "```json" in json_content:
                    json_content = json_content.split("```json")[1].split("```")[0].strip()
                elif "```" in json_content:
                    json_content = json_content.split("```")[1].split("```")[0].strip()
                
                result = json.loads(json_content)
                
                # ê²°ê³¼ ì €ì¥
                scores[risk_id] = result["score"]
                rationale[risk_id] = result["rationale"]
                
            except Exception as e:
                state.error_message = f"ì ìˆ˜ ì˜ˆì¸¡ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.scores = scores
        state.rationale = rationale
        
        return state
        
    except Exception as e:
        state.error_message = f"ì ìˆ˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ì ìˆ˜ ê³„ì‚° ë…¸ë“œ
def score_calculator(state: EthicalRiskState) -> EthicalRiskState:
    """
    ê¸°ë³¸ ì ìˆ˜ì™€ ê°€ì¤‘ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    try:
        # ì ìˆ˜ ì¶”ì¶œ
        scores = state.scores
        risk_items = state.risk_items
        
        # ì°¨ì›ë³„ ì ìˆ˜ ì§‘ê³„
        dimension_scores = {
            "ê³µì •ì„±": [],
            "í”„ë¼ì´ë²„ì‹œ": [],
            "íˆ¬ëª…ì„±": [],
            "ì±…ì„ì„±": [],
            "ì•ˆì „ì„±": []
        }
        
        # ê° ë¦¬ìŠ¤í¬ í•­ëª©ì„ ì°¨ì›ë³„ë¡œ ë¶„ë¥˜
        for risk in risk_items:
            risk_id = risk["id"]
            dimension = risk["dimension"]
            if risk_id in scores:
                dimension_scores[dimension].append(scores[risk_id])
        
        # ì°¨ì›ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
        avg_scores = {}
        for dimension, score_list in dimension_scores.items():
            if score_list:
                avg_scores[dimension] = sum(score_list) / len(score_list)
            else:
                avg_scores[dimension] = 0
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ì „ì²´ í‰ê· )
        all_scores = list(scores.values())
        basic_score = sum(all_scores) / len(all_scores) if all_scores else 0
        
        # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚°
        # ê°€ì¤‘ì¹˜: ê³µì •ì„±(0.25), í”„ë¼ì´ë²„ì‹œ(0.25), íˆ¬ëª…ì„±(0.2), ì±…ì„ì„±(0.15), ì•ˆì „ì„±(0.15)
        weights = {
            "ê³µì •ì„±": 0.25,
            "í”„ë¼ì´ë²„ì‹œ": 0.25,
            "íˆ¬ëª…ì„±": 0.2,
            "ì±…ì„ì„±": 0.15,
            "ì•ˆì „ì„±": 0.15
        }
        
        weighted_score = 0
        for dimension, weight in weights.items():
            weighted_score += avg_scores.get(dimension, 0) * weight
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.risk_scores = {
            "basic": basic_score,
            "weighted": weighted_score,
            "dimension_averages": avg_scores
        }
        
        return state
        
    except Exception as e:
        state.error_message = f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ìœ„í—˜ ë“±ê¸‰ ë¶„ë¥˜ ë…¸ë“œ
def severity_classifier(state: EthicalRiskState) -> EthicalRiskState:
    """
    ê°€ì¤‘ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ ë“±ê¸‰ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    try:
        # ê°€ì¤‘ ì ìˆ˜ ì¶”ì¶œ
        weighted_score = state.risk_scores.get("weighted", 0)
        risk_items = state.risk_items
        scores = state.scores
        
        # ìœ„í—˜ ë“±ê¸‰ ê¸°ì¤€
        thresholds = [
            {"range": [1, 2], "level": "ë‚®ìŒ"},
            {"range": [2.1, 3], "level": "ì¤‘ê°„"},
            {"range": [3.1, 4], "level": "ë†’ìŒ"},
            {"range": [4.1, 5], "level": "ì‹¬ê°"}
        ]
        
        # ì „ì²´ ìœ„í—˜ ë“±ê¸‰ ê²°ì •
        overall_level = "ë‚®ìŒ"  # ê¸°ë³¸ê°’
        for threshold in thresholds:
            min_val, max_val = threshold["range"]
            if min_val <= weighted_score <= max_val:
                overall_level = threshold["level"]
                break
        
        # ê° ë¦¬ìŠ¤í¬ í•­ëª©ì˜ ìœ„í—˜ ë“±ê¸‰ ê²°ì •
        severity_levels = []
        for risk in risk_items:
            risk_id = risk["id"]
            if risk_id in scores:
                score = scores[risk_id]
                
                # ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ê²°ì •
                level = "ë‚®ìŒ"  # ê¸°ë³¸ê°’
                for threshold in thresholds:
                    min_val, max_val = threshold["range"]
                    if min_val <= score <= max_val:
                        level = threshold["level"]
                        break
                
                severity_levels.append({
                    "item_id": risk_id,
                    "level": level,
                    "score": score
                })
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.severity_levels = severity_levels
        
        # ì „ì²´ ìœ„í—˜ ë“±ê¸‰ ì¶”ê°€
        state.risk_scores["overall_level"] = overall_level
        
        return state
        
    except Exception as e:
        state.error_message = f"ìœ„í—˜ ë“±ê¸‰ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ë£¨í”„ ì»¨íŠ¸ë¡¤ëŸ¬ ë…¸ë“œ
def loop_controller(state: EthicalRiskState) -> EthicalRiskState:
    """
    ë¦¬ìŠ¤í¬ ì‹¬ê°ë„ì— ë”°ë¼ ì¬ì§„ë‹¨ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    try:
        # ìœ„í—˜ ë“±ê¸‰ ë° ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
        severity_levels = state.severity_levels
        retry_count = state.retry_count
        
        # ê³ ìœ„í—˜ í•­ëª© í™•ì¸
        high_risk_exists = any(item["level"] in ["ë†’ìŒ", "ì‹¬ê°"] for item in severity_levels)
        
        # ë‹¤ìŒ ë…¸ë“œ ê²°ì •
        if high_risk_exists and retry_count < 3:
            # ê³ ìœ„í—˜ í•­ëª©ì´ ìˆê³  ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šì€ ê²½ìš° ì¬ì§„ë‹¨
            state.next_node = "ScorePredictor"
            state.retry_count += 1
        else:
            # ê³ ìœ„í—˜ í•­ëª©ì´ ì—†ê±°ë‚˜ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•œ ê²½ìš° ê°œì„  ì œì•ˆìœ¼ë¡œ ì´ë™
            state.next_node = "ImprovementAgent"
            state.assessment_status = "completed"
        
        # ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼ ìš”ì•½
        risk_summary = {
            "service_title": state.service_info.get("title", "Unknown Service"),
            "risk_scores": state.risk_scores,
            "severity_levels": state.severity_levels,
            "retry_count": state.retry_count,
            "next_node": state.next_node,
            "timestamp": datetime.now().isoformat()
        }
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.risk_assessments.append(risk_summary)
        
        # ChromaDBì— ê²°ê³¼ ì €ì¥
        vector_store = get_vector_store()
        vector_store.add_texts(
            texts=[json.dumps(risk_summary, ensure_ascii=False, indent=2)],
            metadatas=[{
                "type": "risk_assessment",
                "service_id": state.service_info.get("id", "unknown"),
                "timestamp": datetime.now().isoformat(),
                "overall_level": state.risk_scores.get("overall_level", "unknown")
            }]
        )
        
        return state
        
    except Exception as e:
        state.error_message = f"ë£¨í”„ ì œì–´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸
def risk_assessor(state: EthicalRiskState) -> EthicalRiskState:
    """
    ê°€ì´ë“œë¼ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì„œë¹„ìŠ¤ì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    """
    try:
        print("ğŸ” ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ í‰ê°€ ì‹œì‘...")
        
        # ì„œë¹„ìŠ¤ ì •ë³´ ì¶”ì¶œ
        service_info_text = json.dumps(state.service_info, ensure_ascii=False, indent=2)
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        risk_assessments = []
        
        # ê° ìœ¤ë¦¬ ì°¨ì›ë³„ í‰ê°€
        for category in ["ê³µì •ì„±", "í”„ë¼ì´ë²„ì‹œ", "íˆ¬ëª…ì„±", "ì±…ì„ì„±", "ì•ˆì „ì„±"]:
            print(f"  - {category} ì¹´í…Œê³ ë¦¬ í‰ê°€ ì¤‘...")
            
            # í•´ë‹¹ ì°¨ì›ì˜ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ
            category_guidelines = state.guideline_summary.get(category, [])
            
            # ê°€ì´ë“œë¼ì¸ í…ìŠ¤íŠ¸ ìƒì„± (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            if category_guidelines:
                guidelines_text = "\n\n".join([
                    f"ì¶œì²˜: {item['source']}\në‚´ìš©: {item['content']}" 
                    for item in category_guidelines
                ])
            else:
                # ê°€ì´ë“œë¼ì¸ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ ê°€ì´ë“œë¼ì¸ í…ìŠ¤íŠ¸ ì œê³µ
                print(f"  âš ï¸ {category} ê°€ì´ë“œë¼ì¸ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
                guidelines_text = f"{category}ì— ê´€í•œ AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ì˜ ì¼ë°˜ì  ì›ì¹™ì„ ì ìš©í•˜ì„¸ìš”."
            
            # LLMìœ¼ë¡œ ë¦¬ìŠ¤í¬ í‰ê°€
            assessment_prompt = f"""
                        ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ AI ì„œë¹„ìŠ¤ì— ëŒ€í•´ "{category}" ì¸¡ë©´ì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.
                        
                        ## AI ì„œë¹„ìŠ¤ ì •ë³´
                        ```json
                        {service_info_text}
                        ```
                        
                        ## ê´€ë ¨ ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸
                        {guidelines_text}
                        
                        ## ì§€ì‹œì‚¬í•­
                        1. "{category}" ì¸¡ë©´ì—ì„œ ì´ ì„œë¹„ìŠ¤ì˜ ì£¼ìš” ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ 3-5ê°€ì§€ ì‹ë³„í•˜ì„¸ìš”.
                        2. ê° ë¦¬ìŠ¤í¬ì˜ ì‹¬ê°ë„ë¥¼ 'ë‚®ìŒ', 'ì¤‘ê°„', 'ë†’ìŒ', 'ì‹¬ê°' ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•˜ì„¸ìš”.
                        3. ê° ë¦¬ìŠ¤í¬ì— ëŒ€í•œ ê·¼ê±°ì™€ ì˜ˆë°©/ì™„í™” ë°©ì•ˆì„ ì œì•ˆí•˜ì„¸ìš”.
                        4. 1-5ì  ì²™ë„ë¡œ ì´ ì°¨ì›ì˜ ì „ë°˜ì ì¸ ìœ¤ë¦¬ì  ìœ„í—˜ ì ìˆ˜ë¥¼ ë§¤ê¸°ì„¸ìš”.
                        
                        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”:
                        ```json
                        {{
                            "dimension": "{category}",
                            "risks": [
                                {{
                                    "title": "ë¦¬ìŠ¤í¬ ì œëª©",
                                    "severity": "ì¤‘ê°„",
                                    "description": "ë¦¬ìŠ¤í¬ ì„¤ëª…",
                                    "evidence": "ê·¼ê±°",
                                    "mitigation": "ì™„í™” ë°©ì•ˆ"
                                }}
                            ],
                            "overall_score": 3,
                            "rationale": "ì „ë°˜ì ì¸ ì ìˆ˜ì— ëŒ€í•œ ê·¼ê±°"
                        }}
                        ```
                        """
            
            # ë©”ì‹œì§€ ìƒì„±
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§€ì‹œì— ë”°ë¼ AI ì„œë¹„ìŠ¤ì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ì„¸ìš”."),
                HumanMessage(content=assessment_prompt)
            ]
            
            try:
                # LLMìœ¼ë¡œ ë¦¬ìŠ¤í¬ í‰ê°€
                response = llm.invoke(messages)
                
                # JSON ì¶”ì¶œ
                try:
                    # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    json_content = response.content
                    if "```json" in json_content:
                        json_content = json_content.split("```json")[1].split("```")[0].strip()
                    elif "```" in json_content:
                        json_content = json_content.split("```")[1].split("```")[0].strip()
                    
                    assessment = json.loads(json_content)
                    risk_assessments.append(assessment)
                    print(f"  âœ“ {category} í‰ê°€ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"  âš ï¸ {category} í‰ê°€ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±
                    fallback_assessment = {
                        "dimension": category,
                        "risks": [
                            {
                                "title": f"{category} ê´€ë ¨ ë¦¬ìŠ¤í¬",
                                "severity": "ì¤‘ê°„",
                                "description": "ìë™ ìƒì„±ëœ ê¸°ë³¸ ë¦¬ìŠ¤í¬ í•­ëª©",
                                "evidence": "JSON íŒŒì‹± ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ í•­ëª©",
                                "mitigation": "ìƒì„¸ ë¦¬ìŠ¤í¬ í‰ê°€ í•„ìš”"
                            }
                        ],
                        "overall_score": 3,
                        "rationale": "JSON íŒŒì‹± ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ í‰ê°€"
                    }
                    risk_assessments.append(fallback_assessment)
                    
            except Exception as e:
                print(f"  âš ï¸ {category} í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        print(f"âœ… ì´ {len(risk_assessments)}ê°œ ì¹´í…Œê³ ë¦¬ í‰ê°€ ì™„ë£Œ")
        state.risk_assessments = risk_assessments
        state.assessment_status = "completed"
        
        return state
        
    except Exception as e:
        state.error_message = f"ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        print(f"âŒ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
        return state
        
    except Exception as e:
        state.error_message = f"ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        state.assessment_status = "failed"
        return state


# ê·¸ë˜í”„ êµ¬ì„±
def create_ethical_risk_agent() -> StateGraph:
    """ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(EthicalRiskState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("retrieve", guideline_retriever)
    workflow.add_node("extract", risk_item_extractor)
    workflow.add_node("predict", score_predictor)
    workflow.add_node("calculate", score_calculator)
    workflow.add_node("classify", severity_classifier)
    workflow.add_node("control", loop_controller)
    workflow.add_node("assess", risk_assessor)
    
    # ì—£ì§€ ì¶”ê°€
    workflow.add_edge("retrieve", "extract")
    workflow.add_edge("extract", "predict")
    workflow.add_edge("predict", "calculate")
    workflow.add_edge("calculate", "classify")
    workflow.add_edge("classify", "control")
    
    # ìˆ˜ì •: ì¡°ê±´ë¶€ ì—£ì§€ ìˆ˜ì • - í•­ìƒ assess ë…¸ë“œë¡œ ì´ë™í•˜ë„ë¡ ì„¤ì •
    workflow.add_conditional_edges(
        "control",
        lambda state: state.next_node,
        {
            "ScorePredictor": "predict",
            "ImprovementAgent": "assess"
        }
    )
    
    # ìµœì¢… ì—£ì§€ ì¶”ê°€ 
    workflow.add_edge("assess", END)
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("retrieve")
    
    return workflow


# ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def run_ethical_risk_agent(service_info: Dict[str, Any]) -> Dict[str, Any]:
    """ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì—ì´ì „íŠ¸ ì‹œì‘")
    
    # ê·¸ë˜í”„ ìƒì„± ë° ì»´íŒŒì¼
    graph = create_ethical_risk_agent()
    app = graph.compile()
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = EthicalRiskState(service_info=service_info)
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    result = app.invoke(initial_state.dict())
    
    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    print(f"ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì™„ë£Œ: ìƒíƒœ = {result['assessment_status']}")
    print(f"ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼ ìˆ˜: {len(result['risk_assessments'])}")
    
    # ê²°ê³¼ ë°˜í™˜
    return {
        "service_info": result["service_info"],
        "risk_assessments": result["risk_assessments"],
        "assessment_status": result["assessment_status"],
        "timestamp": result["timestamp"],
        "error_message": result.get("error_message")
    }


if __name__ == "__main__":
    # Microsoft Azure AI Vision Face API í…ŒìŠ¤íŠ¸
    test_service_info = {
        "title": "Microsoft Azure AI Vision Face API",
        "domain": "ì»´í“¨í„° ë¹„ì „ / ì–¼êµ´ ì¸ì‹",
        "summary": "ì–¼êµ´ ê°ì§€, ì‹ë³„, ê°ì • ë¶„ì„ ë“± ì–¼êµ´ ê´€ë ¨ ì»´í“¨í„° ë¹„ì „ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë¼ìš°ë“œ API ì„œë¹„ìŠ¤",
        "features": [
            {"name": "ì–¼êµ´ ê°ì§€", "description": "ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ìœ„ì¹˜ ë° íŠ¹ì§•ì  ê°ì§€"},
            {"name": "ì–¼êµ´ ì¸ì‹", "description": "ê°œì¸ ì‹ë³„ ë° ìœ ì‚¬ë„ ë¶„ì„"},
            {"name": "ê°ì • ë¶„ì„", "description": "í‘œì • ê¸°ë°˜ ê°ì • ìƒíƒœ ì¶”ì •"},
            {"name": "ì†ì„± ë¶„ì„", "description": "ë‚˜ì´, ì„±ë³„ ë“± ì¸êµ¬í†µê³„í•™ì  ì†ì„± ì¶”ì •"}
        ],
        "target_users": [
            "ë³´ì•ˆ ì‹œìŠ¤í…œ ê°œë°œì", "ë§ˆì¼€íŒ… ë¶„ì„ê°€", "UX ì—°êµ¬ì›", "ì ‘ê·¼ì„± ê°œë°œì"
        ],
        "data_sources": [
            "ì‚¬ìš©ì ì—…ë¡œë“œ ì´ë¯¸ì§€", "ë¹„ë””ì˜¤ í”„ë ˆì„", "ì €ì¥ëœ ì–¼êµ´ í…œí”Œë¦¿"
        ],
        "algorithms": [
            "ë”¥ëŸ¬ë‹ CNN", "ì–¼êµ´ ì„ë² ë”©", "íŠ¹ì§•ì  ì¶”ì¶œ"
        ]
    }
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    result = run_ethical_risk_agent(test_service_info)
    print(json.dumps(result, ensure_ascii=False, indent=2))