import os
import sys
import json
from typing import Dict, List, Any
from datetime import datetime
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from utils.vector_db import VectorDBManager
from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper

# ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜
class ServiceAnalysisState(BaseModel):
    # ì…ë ¥
    service_name: str = Field(default="", description="ë¶„ì„ ëŒ€ìƒ AI ì„œë¹„ìŠ¤ì˜ ì´ë¦„")
    service_description: str = Field(default="", description="ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì´ˆê¸° ì„¤ëª…")
    additional_data: Dict[str, Any] = Field(default_factory=dict, description="ì¶”ê°€ ì •ë³´ ë° ì°¸ê³  ìë£Œ")
    
    # ì¶œë ¥
    doc_id: str = Field(default="", description="ì„œë¹„ìŠ¤ ê°œìš” ë¬¸ì„œ ê³ ìœ  ì‹ë³„ì")
    chunk_ids: List[str] = Field(default_factory=list, description="ë¶„í•  ì²­í¬ ID ëª©ë¡")
    summary: Dict[str, Any] = Field(default_factory=dict, description="ì„œë¹„ìŠ¤ ê°œìš” ìš”ì•½")
    search_results: List[Dict[str, Any]] = Field(default_factory=list, description="ê²€ìƒ‰ ê²°ê³¼")
    
    # ì œì–´
    status: str = Field(default="", description="ë¶„ì„ ìƒíƒœ (processing, completed, failed)")
    error_message: str = Field(default="", description="ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ì‹œì§€")
    timestamp: str = Field(default="", description="ë¶„ì„ ìˆ˜í–‰ ì‹œê°„")

# ì„œë¹„ìŠ¤ ì •ë³´ ê²€ìƒ‰ í•¨ìˆ˜
def search_service_info(service_name: str, service_description: str = "") -> Dict[str, Any]:
    """
    Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    try:
        # Tavily API í‚¤ í™•ì¸
        tavily_api_key = os.getenv("TAVILY_API_KEY")
        if not tavily_api_key:
            print("âš ï¸ Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"error": "Tavily API í‚¤ ì—†ìŒ"}
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        search_query = f"{service_name} AI service features and technology"
        if service_description:
            search_query += f" {service_description}"
        
        # Tavily ê²€ìƒ‰ ì‹¤í–‰
        search = TavilySearchAPIWrapper()
        search_results = search.results(search_query, max_results=5)
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
        extracted_info = {
            "description": "",
            "features": [],
            "target_users": "",
            "tech_stack": "",
            "search_results": search_results
        }
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì£¼ìš” í…ìŠ¤íŠ¸ í†µí•©
        combined_text = ""
        for result in search_results:
            if "content" in result:
                combined_text += result["content"] + "\n\n"
        
        extracted_info["description"] = combined_text[:500] + "..." if len(combined_text) > 500 else combined_text
        
        return extracted_info
        
    except Exception as e:
        print(f"âš ï¸ ì„œë¹„ìŠ¤ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {"error": str(e)}

# ì—ì´ì „íŠ¸ ë…¸ë“œ: ì„œë¹„ìŠ¤ ì •ë³´ ë¶„ì„
def analyze_service(state: ServiceAnalysisState) -> ServiceAnalysisState:
    """
    AI ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” íŠ¹ì§•, ëŒ€ìƒ ê¸°ëŠ¥, ì‚¬ìš©ì ê·¸ë£¹ ë“±ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” ì„œë¹„ìŠ¤ ì •ë³´ ë¶„ì„ ì‹œì‘: {state.service_name}")
    timestamp = datetime.now().isoformat()
    
    try:
        # OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„œë¹„ìŠ¤ ì •ë³´ í™•ì¸
        if not state.service_name:
            raise ValueError("ë¶„ì„í•  ì„œë¹„ìŠ¤ ì´ë¦„ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„œë¹„ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - Tavily ê²€ìƒ‰ ì‚¬ìš©
        print(f"ğŸŒ '{state.service_name}' ì •ë³´ ê²€ìƒ‰ ì¤‘...")
        service_info = search_service_info(state.service_name, state.service_description)
        
        # ê²€ìƒ‰ ì˜¤ë¥˜ í™•ì¸
        if "error" in service_info:
            print(f"âš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜: {service_info['error']}")
            # ê¸°ë³¸ ì„œë¹„ìŠ¤ ì„¤ëª… ì‚¬ìš©
            if state.service_description:
                service_info = {"description": state.service_description}
            else:
                service_info = {"description": f"{state.service_name}ì— ëŒ€í•œ AI ì„œë¹„ìŠ¤ ì •ë³´"}
        
        # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ ë³‘í•©
        if state.additional_data:
            service_info.update(state.additional_data)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
        search_results = service_info.pop("search_results", []) if "search_results" in service_info else []
        
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(temperature=0, model="gpt-4o-mini", openai_api_key=openai_api_key)
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
        template = """
        ë‹¹ì‹ ì€ AI ì„œë¹„ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ AI ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê°œìš”ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        
        ì„œë¹„ìŠ¤ ì •ë³´:
        - ì´ë¦„: {service_name}
        - ì„¤ëª…: {service_description}
        - ê²€ìƒ‰ëœ ì •ë³´: {search_results}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ëœ JSONì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        ```json
        {{
            "service_name": "ì„œë¹„ìŠ¤ ì´ë¦„",
            "type": "ì„œë¹„ìŠ¤ ìœ í˜•(ì¶”ì²œ, ìƒì„±í˜•, ë¶„ë¥˜, ì˜ˆì¸¡ ë“±)",
            "description": "250ì ë‚´ì™¸ ì„œë¹„ìŠ¤ ê°œìš”",
            "primary_features": ["ì£¼ìš” ê¸°ëŠ¥ 1", "ì£¼ìš” ê¸°ëŠ¥ 2", "ì£¼ìš” ê¸°ëŠ¥ 3"],
            "target_users": ["ëŒ€ìƒ ì‚¬ìš©ì ê·¸ë£¹ 1", "ëŒ€ìƒ ì‚¬ìš©ì ê·¸ë£¹ 2"],
            "data_sources": ["ì‚¬ìš© ë°ì´í„° ì†ŒìŠ¤ 1", "ì‚¬ìš© ë°ì´í„° ì†ŒìŠ¤ 2"],
            "technology": ["ì‚¬ìš© ê¸°ìˆ  1", "ì‚¬ìš© ê¸°ìˆ  2"],
            "ethical_concerns": ["ì ì¬ì  ìœ¤ë¦¬ ì´ìŠˆ 1", "ì ì¬ì  ìœ¤ë¦¬ ì´ìŠˆ 2", "ì ì¬ì  ìœ¤ë¦¬ ì´ìŠˆ 3"],
            "analysis_scope": ["ì§„ë‹¨ ë²”ìœ„ í•­ëª© 1", "ì§„ë‹¨ ë²”ìœ„ í•­ëª© 2", "ì§„ë‹¨ ë²”ìœ„ í•­ëª© 3"]
        }}
        ```
        
        íŠ¹íˆ ethical_concernsì™€ analysis_scopeëŠ” í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ìœ¤ë¦¬ì  ì§„ë‹¨ì´ í•„ìš”í•œ í•­ëª©ë“¤ì„ 5ê°œ ì´ë‚´ë¡œ ì •í™•íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ì ì¬ì  ìœ¤ë¦¬ ì´ìŠˆì—ëŠ” í¸í–¥ì„±, í”„ë¼ì´ë²„ì‹œ, íˆ¬ëª…ì„±, ì•ˆì „ì„± ë“±ì˜ ê´€ì ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        ê²€ìƒ‰ ê²°ê³¼ê°€ ì œí•œì ì´ê±°ë‚˜ ë¶ˆëª…í™•í•œ ê²½ìš°ì—ëŠ” ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ ì¼ë°˜ì ì¸ AI ì„œë¹„ìŠ¤ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœëŒ€í•œ í•©ë¦¬ì ì¸ ì¶”ë¡ ì„ í†µí•´ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        search_results_text = ""
        for i, result in enumerate(search_results):
            search_results_text += f"\n[{i+1}] ì œëª©: {result.get('title', 'No Title')}\n"
            search_results_text += f"ë‚´ìš©: {result.get('content', 'No Content')[:500]}...\n"
            search_results_text += f"URL: {result.get('url', 'No URL')}\n"
        
        if not search_results_text:
            search_results_text = "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
        
        # í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ ê°’ ì¤€ë¹„
        prompt_values = {
            "service_name": state.service_name,
            "service_description": service_info.get("description", ""),
            "search_results": search_results_text
        }
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | llm
        response = chain.invoke(prompt_values)
        
        # JSON ì‘ë‹µ íŒŒì‹±
        response_text = response.content
        json_start = response_text.find('```json')
        json_end = response_text.rfind('```')
        
        if json_start >= 0 and json_end > json_start:
            json_text = response_text[json_start+7:json_end].strip()
            service_summary = json.loads(json_text)
        else:
            service_summary = json.loads(response_text)
        
        # VectorDBì— ì €ì¥
        db_manager = VectorDBManager()
        collection_name = "service_info"
        
        # ì»¬ë ‰ì…˜ ìƒì„± (ì—†ëŠ” ê²½ìš°)
        if not db_manager.collection_exists(collection_name):
            db_manager.create_collection(collection_name)
        
        # ì„œë¹„ìŠ¤ ì •ë³´ ì €ì¥
        doc_content = json.dumps(service_summary, ensure_ascii=False, indent=2)
        metadata = {
            "service_name": state.service_name,
            "timestamp": timestamp,
            "content_type": "service_summary"
        }
        
        doc_id = db_manager.add_document(
            collection_name=collection_name,
            content=doc_content,
            metadata=metadata
        )[0]
        
        # ì²­í¬ ì²˜ë¦¬ - ì‹¤ì œ ìƒí™©ì—ì„œëŠ” í•„ìš”ì‹œ ì„œë¹„ìŠ¤ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥
        chunk_ids = []
        
        # ê²°ê³¼ ë°˜í™˜
        print(f"âœ… ì„œë¹„ìŠ¤ ë¶„ì„ ì™„ë£Œ: {state.service_name}")
        
        return ServiceAnalysisState(
            service_name=state.service_name,
            service_description=state.service_description,
            additional_data=state.additional_data,
            doc_id=doc_id,
            chunk_ids=chunk_ids,
            summary=service_summary,
            search_results=search_results,
            status="completed",
            timestamp=timestamp
        )
        
    except Exception as e:
        error_message = f"ì„œë¹„ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"âŒ {error_message}")
        
        return ServiceAnalysisState(
            service_name=state.service_name,
            service_description=state.service_description,
            additional_data=state.additional_data,
            status="failed",
            error_message=error_message,
            timestamp=timestamp
        )

# ì—ì´ì „íŠ¸ ë…¸ë“œ: ì§„ë‹¨ ë²”ìœ„ ì œì•ˆ
def suggest_analysis_scope(state: ServiceAnalysisState) -> ServiceAnalysisState:
    """
    ì„œë¹„ìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ¤ë¦¬ì  ì§„ë‹¨ ë²”ìœ„ë¥¼ í™•ì •í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ“‹ ì§„ë‹¨ ë²”ìœ„ ì œì•ˆ ì‹œì‘: {state.service_name}")
    
    # ì´ë¯¸ ë¶„ì„ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
    if state.status == "failed":
        return state
    
    try:
        # ì´ë¯¸ ë¶„ì„ëœ ìš”ì•½ ì •ë³´ì—ì„œ ì§„ë‹¨ ë²”ìœ„ ì¶”ì¶œ (ethical_concerns, analysis_scope)
        if "ethical_concerns" in state.summary and "analysis_scope" in state.summary:
            # ì´ë¯¸ ì§„ë‹¨ ë²”ìœ„ê°€ ê²°ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì‘ì—… ì—†ì´ ì™„ë£Œ ì²˜ë¦¬
            print(f"âœ… ì§„ë‹¨ ë²”ìœ„ í™•ì • ì™„ë£Œ: {state.service_name}")
            return state
        else:
            # ìš”ì•½ ë°ì´í„°ì— ì§„ë‹¨ ë²”ìœ„ê°€ ì—†ëŠ” ê²½ìš° - ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ í†µí•´ ì¶”ê°€ ë¶„ì„ ê°€ëŠ¥
            print(f"âš ï¸ ì„œë¹„ìŠ¤ ìš”ì•½ì— ì§„ë‹¨ ë²”ìœ„ê°€ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë²”ìœ„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # ê¸°ë³¸ ì§„ë‹¨ ë²”ìœ„ ì„¤ì •
            state.summary.update({
                "ethical_concerns": [
                    "ë°ì´í„° í¸í–¥ì„±",
                    "í”„ë¼ì´ë²„ì‹œ ì¹¨í•´",
                    "íˆ¬ëª…ì„±ê³¼ ì„¤ëª…ê°€ëŠ¥ì„±",
                    "ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„±",
                    "ì±…ì„ì„±"
                ],
                "analysis_scope": [
                    "í¸í–¥ì„± í‰ê°€ ë° ì™„í™” ë°©ì•ˆ",
                    "ê°œì¸ì •ë³´ ìˆ˜ì§‘Â·ì´ìš©Â·ë³´í˜¸",
                    "ì˜ì‚¬ê²°ì • ê³¼ì • íˆ¬ëª…ì„±",
                    "ì‹œìŠ¤í…œ ì•ˆì „ì„± ê²€ì¦",
                    "ì±…ì„ ì†Œì¬ ëª…í™•í™”"
                ]
            })
            
            # ì—…ë°ì´íŠ¸ëœ ìš”ì•½ ì •ë³´ ë‹¤ì‹œ ì €ì¥
            if state.doc_id:
                db_manager = VectorDBManager()
                doc_content = json.dumps(state.summary, ensure_ascii=False, indent=2)
                metadata = {
                    "service_name": state.service_name,
                    "timestamp": datetime.now().isoformat(),
                    "content_type": "service_summary_updated"
                }
                
                db_manager.update_document(
                    collection_name="service_info",
                    doc_id=state.doc_id,
                    content=doc_content,
                    metadata=metadata
                )
            
            return state
            
    except Exception as e:
        error_message = f"ì§„ë‹¨ ë²”ìœ„ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"âŒ {error_message}")
        
        return ServiceAnalysisState(
            service_name=state.service_name,
            service_description=state.service_description,
            additional_data=state.additional_data,
            doc_id=state.doc_id,
            chunk_ids=state.chunk_ids,
            summary=state.summary,
            search_results=state.search_results,
            status="failed",
            error_message=error_message,
            timestamp=datetime.now().isoformat()
        )

# ì›Œí¬í”Œë¡œìš° ì œì–´ í•¨ìˆ˜
def router(state: ServiceAnalysisState) -> str:
    """ìƒíƒœì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    if state.status == "failed":
        return "end"  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¢…ë£Œ
    elif not state.summary:  # ì•„ì§ ë¶„ì„ë˜ì§€ ì•Šì€ ê²½ìš°
        return "analyze"
    else:
        return "scope"  # ë¶„ì„ì´ ì™„ë£Œë˜ì–´ ë²”ìœ„ ì œì•ˆìœ¼ë¡œ ì´ë™

# ê·¸ë˜í”„ êµ¬ì„±
def create_service_analysis_graph() -> StateGraph:
    """ì„œë¹„ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(ServiceAnalysisState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("analyze", analyze_service)
    workflow.add_node("scope", suggest_analysis_scope)
    
    # ì œì–´ íë¦„ ì„¤ì •
    workflow.add_conditional_edges(
        "analyze",  # ì‹œì‘ ë…¸ë“œ
        router,     # ë¼ìš°íŒ… í•¨ìˆ˜
        {
            "analyze": "analyze",  # ë¶„ì„ ë…¸ë“œë¡œ ì´ë™
            "scope": "scope",     # ë²”ìœ„ ì œì•ˆ ë…¸ë“œë¡œ ì´ë™
            "end": END           # ì¢…ë£Œ
        }
    )
    
    # ë²”ìœ„ ì œì•ˆ ë…¸ë“œì—ì„œ ì¢…ë£Œë¡œ ê°€ëŠ” ì—£ì§€
    workflow.add_edge("scope", END)
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("analyze")
    
    return workflow

# ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
def run_service_analysis_agent(service_name: str, service_description: str = "", additional_data: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ì„œë¹„ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ ì„œë¹„ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œì‘: {service_name}")
    
    # ê·¸ë˜í”„ ìƒì„± ë° ì»´íŒŒì¼
    graph = create_service_analysis_graph()
    app = graph.compile()
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = ServiceAnalysisState(
        service_name=service_name,
        service_description=service_description,
        additional_data=additional_data or {}
    )
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    try:
        result = app.invoke(initial_state)
        
        # ê²°ê³¼ëŠ” ë”•ì…”ë„ˆë¦¬ì²˜ëŸ¼ ì ‘ê·¼í•´ì•¼ í•¨ (AddableValuesDict íƒ€ì…)
        if "status" in result and result["status"] == "completed":
            print(f"âœ… ì„œë¹„ìŠ¤ ë¶„ì„ ì„±ê³µ: {service_name}")
            return {
                "service_name": result["service_name"],
                "doc_id": result["doc_id"],
                "chunk_ids": result["chunk_ids"],
                "summary": result["summary"],
                "status": "completed",
                "timestamp": result["timestamp"]
            }
        else:
            error_msg = result.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            print(f"âŒ ì„œë¹„ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
            return {
                "service_name": service_name,
                "status": "failed",
                "error_message": error_msg,
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        error_message = f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"âŒ {error_message}")
        return {
            "service_name": service_name,
            "status": "failed", 
            "error_message": error_message,
            "timestamp": datetime.now().isoformat()
        }

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    # Microsoft Azure AI Vision Face API í…ŒìŠ¤íŠ¸
    service_name = "Microsoft Azure AI Vision Face API"
    service_description = "ì–¼êµ´ ê°ì§€, ì‹ë³„, ê°ì • ë¶„ì„ ë“± ì–¼êµ´ ê´€ë ¨ ì»´í“¨í„° ë¹„ì „ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë¼ìš°ë“œ API ì„œë¹„ìŠ¤"
    
    # í…ŒìŠ¤íŠ¸ ì‹œ API í‚¤ í™•ì¸
    print(f"OpenAI API í‚¤ ìƒíƒœ: {'ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
    print(f"Tavily API í‚¤ ìƒíƒœ: {'ì„¤ì •ë¨' if os.getenv('TAVILY_API_KEY') else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
    
    # ì—ì´ì „íŠ¸ ì‹¤í–‰ - ì´ì œ ì§ì ‘ ì„œë¹„ìŠ¤ ì •ë³´ ì „ë‹¬
    result = run_service_analysis_agent(
        service_name=service_name,
        service_description=service_description
    )
    
    if result["status"] == "completed":
        print("\n===== ì„œë¹„ìŠ¤ ë¶„ì„ ê²°ê³¼ =====")
        for key, value in result["summary"].items():
            if isinstance(value, list):
                print(f"{key}:")
                for item in value:
                    print(f"  - {item}")
            else:
                print(f"{key}: {value}")
    else:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")